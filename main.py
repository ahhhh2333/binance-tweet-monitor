#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¸å®‰æ¨ç‰¹ç›‘æ§æœºå™¨äºº - ç®€åŒ–ç‰ˆ
ç›‘æ§@binancezhçš„Alphaç§¯åˆ†æ¨æ–‡å¹¶è‡ªåŠ¨æ¨é€åˆ°ä¼ä¸šå¾®ä¿¡
"""

import os
import json
import time
import requests
import logging
from datetime import datetime, timezone, timedelta
from typing import List, Dict, Any, Optional

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class BinanceTwitterMonitor:
    def __init__(self):
        # è·å–é…ç½®
        self.bearer_tokens = self._get_bearer_tokens()
        self.wechat_webhook = os.getenv('WECHAT_WEBHOOK_URL', '')
        self.target_user = 'binancezh'
        self.current_token_index = 0
        
        # æ‰©å±•çš„Alphaå…³é”®è¯åˆ—è¡¨
        self.alpha_keywords = [
            # åŸºç¡€Alphaå…³é”®è¯
            'alpha', 'Alpha', 'ALPHA', 'aplha', 'Aplha',
            
            # ç§¯åˆ†ç›¸å…³
            'ç§¯åˆ†', 'points', 'Points', 'point', 'Point',
            
            # ç©ºæŠ•ç›¸å…³
            'ç©ºæŠ•', 'airdrop', 'Airdrop', 'AIRDROP',
            'airdrops', 'Airdrops', 'AIRDROPS',
            
            # æ´»åŠ¨ç›¸å…³
            'é¢†å–', 'claim', 'Claim', 'CLAIM',
            'ç”³é¢†', 'ä»£å¸ç©ºæŠ•',
            
            # ç»„åˆå…³é”®è¯
            'Alphaç§¯åˆ†', 'alphaç§¯åˆ†', 'Alpha Points', 'alpha points',
            'Alphaç©ºæŠ•', 'alphaç©ºæŠ•', 'ALPHAç©ºæŠ•',
            'å¸å®‰Alpha', 'å¸å®‰alpha', 'Binance Alpha', 'binance alpha',
            
            # å¥–åŠ±ç›¸å…³
            'å¥–åŠ±', 'reward', 'Reward', 'REWARD', 'rewards'
        ]
        
        # æ•°æ®æ–‡ä»¶
        self.data_file = 'processed_tweets.json'
        self.processed_data = self._load_processed_tweets()
        
        logger.info(f"åˆå§‹åŒ–å®Œæˆï¼Œå…±{len(self.bearer_tokens)}ä¸ªTokenï¼Œ{len(self.alpha_keywords)}ä¸ªå…³é”®è¯")
    
    def _get_bearer_tokens(self) -> List[str]:
        """è·å–æ‰€æœ‰Bearer Token"""
        tokens = []
        
        # è·å–ç¼–å·çš„token (1-8)
        for i in range(1, 9):
            token = os.getenv(f'TWITTER_BEARER_TOKEN_{i}', '')
            if token:
                tokens.append(token)
        
        # å¦‚æœæ²¡æœ‰ç¼–å·tokenï¼Œå°è¯•è·å–åŸºç¡€token
        if not tokens:
            base_token = os.getenv('TWITTER_BEARER_TOKEN', '')
            if base_token:
                tokens.append(base_token)
        
        if not tokens:
            raise ValueError("æœªæ‰¾åˆ°Twitter Bearer Token")
        
        return tokens
    
    def _load_processed_tweets(self) -> Dict[str, Any]:
        """åŠ è½½å·²å¤„ç†çš„æ¨æ–‡æ•°æ®"""
        try:
            if os.path.exists(self.data_file):
                with open(self.data_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    # ç¡®ä¿æ•°æ®ç»“æ„æ­£ç¡®
                    if 'processed_ids' not in data:
                        data['processed_ids'] = []
                    if 'alpha_sent_ids' not in data:
                        data['alpha_sent_ids'] = []
                    return data
        except Exception as e:
            logger.error(f"åŠ è½½æ•°æ®æ–‡ä»¶å¤±è´¥: {e}")
        
        return {
            'processed_ids': [],      # æ‰€æœ‰å·²å¤„ç†çš„æ¨æ–‡ID
            'alpha_sent_ids': [],     # å·²å‘é€è¿‡Alphaé€šçŸ¥çš„æ¨æ–‡ID
            'last_update': None
        }
    
    def _save_processed_tweets(self):
        """ä¿å­˜å·²å¤„ç†çš„æ¨æ–‡æ•°æ®"""
        try:
            # åªä¿ç•™æœ€è¿‘1000æ¡è®°å½•
            self.processed_data['processed_ids'] = self.processed_data['processed_ids'][-1000:]
            self.processed_data['alpha_sent_ids'] = self.processed_data['alpha_sent_ids'][-1000:]
            self.processed_data['last_update'] = datetime.now().isoformat()
            
            with open(self.data_file, 'w', encoding='utf-8') as f:
                json.dump(self.processed_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"ä¿å­˜æ•°æ®æ–‡ä»¶å¤±è´¥: {e}")
    
    def _is_monitoring_time(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦åœ¨ç›‘æ§æ—¶é—´å†…ï¼ˆåŒ—äº¬æ—¶é—´11:00-23:00ï¼‰"""
        beijing_tz = timezone(timedelta(hours=8))
        beijing_time = datetime.now(beijing_tz)
        return 11 <= beijing_time.hour <= 23
    
    def _get_next_token(self) -> str:
        """è·å–ä¸‹ä¸€ä¸ªå¯ç”¨Token"""
        token = self.bearer_tokens[self.current_token_index]
        self.current_token_index = (self.current_token_index + 1) % len(self.bearer_tokens)
        return token
    
    def _make_twitter_request(self, url: str, params: Dict) -> Optional[Dict]:
        """å‘èµ·Twitter APIè¯·æ±‚ï¼Œè‡ªåŠ¨è½®æ¢Token"""
        for attempt in range(len(self.bearer_tokens)):
            token = self._get_next_token()
            headers = {
                'Authorization': f'Bearer {token}',
                'User-Agent': 'BinanceTweetMonitor/1.0'
            }
            
            try:
                response = requests.get(url, headers=headers, params=params, timeout=10)
                
                if response.status_code == 200:
                    return response.json()
                elif response.status_code == 429:
                    logger.warning(f"Tokenè¾¾åˆ°é™åˆ¶ï¼Œåˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªToken")
                    continue
                else:
                    logger.error(f"APIè¯·æ±‚å¤±è´¥: {response.status_code}")
                    return None
                    
            except Exception as e:
                logger.error(f"è¯·æ±‚å¼‚å¸¸: {e}")
                continue
        
        logger.error("æ‰€æœ‰Tokenéƒ½ä¸å¯ç”¨")
        return None
    
    def get_single_tweet(self, tweet_id: str) -> Optional[Dict]:
        """è·å–å•æ¡æ¨æ–‡çš„å®Œæ•´å†…å®¹"""
        url = f"https://api.twitter.com/2/tweets/{tweet_id}"
        params = {
            'tweet.fields': 'created_at,public_metrics,entities,context_annotations',
            'expansions': 'author_id'
        }
        
        result = self._make_twitter_request(url, params)
        if result and 'data' in result:
            return result['data']
        return None
    
    def get_user_tweets(self) -> List[Dict]:
        """è·å–ç”¨æˆ·æ¨æ–‡"""
        # å…ˆè·å–ç”¨æˆ·ID
        user_url = f"https://api.twitter.com/2/users/by/username/{self.target_user}"
        user_params = {'user.fields': 'id'}
        
        user_data = self._make_twitter_request(user_url, user_params)
        if not user_data or 'data' not in user_data:
            logger.error("è·å–ç”¨æˆ·ä¿¡æ¯å¤±è´¥")
            return []
        
        user_id = user_data['data']['id']
        
        # è·å–æ¨æ–‡åˆ—è¡¨ - æ”¹ä¸º5æ¡ä»¥èŠ‚çœAPIé¢åº¦
        tweets_url = f"https://api.twitter.com/2/users/{user_id}/tweets"
        tweets_params = {
            'max_results': 5,
            'tweet.fields': 'created_at,public_metrics,entities,context_annotations',
            'exclude': 'retweets,replies'
        }
        
        tweets_data = self._make_twitter_request(tweets_url, tweets_params)
        if not tweets_data or 'data' not in tweets_data:
            return []
        
        # è·å–æ¯æ¡æ¨æ–‡çš„å®Œæ•´å†…å®¹
        complete_tweets = []
        for tweet in tweets_data['data']:
            # å¦‚æœæ¨æ–‡çœ‹èµ·æ¥è¢«æˆªæ–­äº†ï¼Œè·å–å®Œæ•´å†…å®¹
            if len(tweet['text']) >= 275 or tweet['text'].endswith('â€¦'):
                logger.info(f"æ¨æ–‡ {tweet['id']} å¯èƒ½è¢«æˆªæ–­ï¼Œè·å–å®Œæ•´å†…å®¹")
                complete_tweet = self.get_single_tweet(tweet['id'])
                if complete_tweet:
                    complete_tweets.append(complete_tweet)
                else:
                    complete_tweets.append(tweet)
            else:
                complete_tweets.append(tweet)
        
        return complete_tweets
    
    def contains_alpha_keywords(self, text: str) -> List[str]:
        """æ£€æŸ¥æ˜¯å¦åŒ…å«Alphaå…³é”®è¯ï¼Œè¿”å›åŒ¹é…çš„å…³é”®è¯åˆ—è¡¨"""
        text_lower = text.lower()
        matched_keywords = []
        
        for keyword in self.alpha_keywords:
            if keyword.lower() in text_lower:
                matched_keywords.append(keyword)
        
        # æ·»åŠ è°ƒè¯•æ—¥å¿—
        logger.info(f"æ£€æŸ¥æ¨æ–‡: {text[:100]}...")
        if matched_keywords:
            logger.info(f"åŒ¹é…åˆ°å…³é”®è¯: {matched_keywords}")
        else:
            logger.info("æœªåŒ¹é…åˆ°ä»»ä½•å…³é”®è¯")
        
        return matched_keywords
    
    def send_wechat_message(self, content: str) -> bool:
        """å‘é€ä¼ä¸šå¾®ä¿¡æ¶ˆæ¯"""
        if not self.wechat_webhook:
            logger.warning("æœªé…ç½®å¾®ä¿¡webhook")
            return False
        
        try:
            # ä¼ä¸šå¾®ä¿¡æ¶ˆæ¯é•¿åº¦é™åˆ¶ï¼Œå¦‚æœå¤ªé•¿å°±æˆªæ–­
            if len(content.encode('utf-8')) > 3800:
                content = content[:1800] + "\n\n...(å†…å®¹è¾ƒé•¿ï¼Œè¯·ç‚¹å‡»é“¾æ¥æŸ¥çœ‹å®Œæ•´å†…å®¹)"
            
            data = {
                "msgtype": "text",
                "text": {"content": content}
            }
            
            response = requests.post(
                self.wechat_webhook,
                json=data,
                headers={'Content-Type': 'application/json'},
                timeout=10
            )
            
            if response.status_code == 200:
                result = response.json()
                if result.get('errcode') == 0:
                    logger.info("å¾®ä¿¡æ¶ˆæ¯å‘é€æˆåŠŸ")
                    return True
                else:
                    logger.error(f"å¾®ä¿¡æ¶ˆæ¯å‘é€å¤±è´¥: {result}")
            
        except Exception as e:
            logger.error(f"å‘é€å¾®ä¿¡æ¶ˆæ¯å¼‚å¸¸: {e}")
        
        return False
    
    def format_message(self, tweet: Dict, matched_keywords: List[str]) -> str:
        """æ ¼å¼åŒ–æ¨æ–‡æ¶ˆæ¯"""
        beijing_tz = timezone(timedelta(hours=8))
        tweet_time = datetime.fromisoformat(tweet['created_at'].replace('Z', '+00:00'))
        beijing_time = tweet_time.astimezone(beijing_tz)
        
        tweet_url = f"https://twitter.com/{self.target_user}/status/{tweet['id']}"
        
        # è·å–å®Œæ•´æ¨æ–‡å†…å®¹
        full_text = tweet['text']
        
        return f"""ğŸ“ å†…å®¹: {full_text}

ğŸ• æ—¶é—´: {beijing_time.strftime('%Y-%m-%d %H:%M:%S')} (åŒ—äº¬æ—¶é—´)

ğŸ”— é“¾æ¥: {tweet_url}"""
    
    def run(self):
        """è¿è¡Œç›‘æ§"""
        try:
            logger.info("å¼€å§‹æ‰§è¡Œæ¨ç‰¹ç›‘æ§")
            logger.info(f"å½“å‰æ—¶é—´: {datetime.now()}")
            
            # æ£€æŸ¥ç›‘æ§æ—¶é—´
            if not self._is_monitoring_time():
                logger.info("å½“å‰ä¸åœ¨ç›‘æ§æ—¶é—´èŒƒå›´å†…ï¼ˆåŒ—äº¬æ—¶é—´11:00-23:00ï¼‰")
                return
            
            # è·å–æ¨æ–‡
            tweets = self.get_user_tweets()
            if not tweets:
                logger.info("æœªè·å–åˆ°æ¨æ–‡")
                return
            
            logger.info(f"è·å–åˆ° {len(tweets)} æ¡æ¨æ–‡")
            
            # å¤„ç†æ–°æ¨æ–‡
            new_alpha_tweets = []
            for tweet in tweets:
                tweet_id = tweet['id']
                tweet_text = tweet['text']
                
                logger.info(f"æ£€æŸ¥æ¨æ–‡ {tweet_id}: {tweet_text[:50]}...")
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«Alphaå…³é”®è¯
                matched_keywords = self.contains_alpha_keywords(tweet_text)
                
                if matched_keywords:
                    # æ£€æŸ¥æ˜¯å¦å·²ç»å‘é€è¿‡Alphaé€šçŸ¥
                    if tweet_id in self.processed_data['alpha_sent_ids']:
                        logger.info(f"æ¨æ–‡ {tweet_id} å·²å‘é€è¿‡Alphaé€šçŸ¥ï¼Œè·³è¿‡")
                    else:
                        tweet['matched_keywords'] = matched_keywords
                        new_alpha_tweets.append(tweet)
                        logger.info(f"å‘ç°Alphaæ¨æ–‡: {tweet_id} (é•¿åº¦: {len(tweet_text)}å­—ç¬¦)")
                        # æ ‡è®°ä¸ºå·²å‘é€Alphaé€šçŸ¥
                        self.processed_data['alpha_sent_ids'].append(tweet_id)
                else:
                    logger.info(f"æ¨æ–‡ {tweet_id} ä¸åŒ…å«Alphaå…³é”®è¯")
                
                # æ ‡è®°ä¸ºå·²å¤„ç†ï¼ˆæ— è®ºæ˜¯å¦åŒ…å«Alphaå…³é”®è¯ï¼‰
                if tweet_id not in self.processed_data['processed_ids']:
                    self.processed_data['processed_ids'].append(tweet_id)
            
            # æŒ‰æ—¶é—´é¡ºåºå‘é€é€šçŸ¥ï¼ˆä»æ—§åˆ°æ–°ï¼‰
            new_alpha_tweets.sort(key=lambda x: x['created_at'])
            
            for tweet in new_alpha_tweets:
                matched_keywords = tweet.get('matched_keywords', [])
                message = self.format_message(tweet, matched_keywords)
                self.send_wechat_message(message)
                time.sleep(3)  # é¿å…é¢‘ç‡é™åˆ¶
            
            # ä¿å­˜å¤„ç†è®°å½•
            self._save_processed_tweets()
            
            logger.info(f"ç›‘æ§å®Œæˆï¼Œå¤„ç†äº†{len(new_alpha_tweets)}æ¡Alphaæ¨æ–‡")
            
        except Exception as e:
            logger.error(f"ç›‘æ§æ‰§è¡Œå¤±è´¥: {e}")
            raise

def main():
    """ä¸»å‡½æ•°"""
    try:
        monitor = BinanceTwitterMonitor()
        monitor.run()
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        exit(1)

if __name__ == "__main__":
    main()
